"""
Webã‚µã‚¤ãƒˆã®OCRæ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«
Playwrightã§ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã€ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³è¡¨ç¤ºã®ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ãã®ã¾ã¾OCRã«ã‹ã‘ã¦æ–‡å­—èµ·ã“ã—ã‚’è¡Œã„ã¾ã™ã€‚
"""

import argparse
import sys
import time
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import os
import subprocess
import shutil

import math

from PIL import Image

# Playwrightã®ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒ¬ãƒãƒ¼ã‚¿ãƒ¼ã‚’ç„¡åŠ¹åŒ–ã—ã¦æ¨©é™ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹
os.environ.setdefault("PLAYWRIGHT_SKIP_CRASH_REPORTER", "1")

# Geminié–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import google.generativeai as genai
except ImportError:
    genai = None

try:
    from dotenv import load_dotenv
except ImportError:
    load_dotenv = None

try:
    import requests
except ImportError:  # pragma: no cover - optional dependency
    requests = None

from playwright.sync_api import (
    sync_playwright,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError,
)

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
ENV_PATH = Path(__file__).resolve().parent / ".env"
if load_dotenv is not None:
    load_dotenv(dotenv_path=ENV_PATH)

SCRIPT_DIR = Path(__file__).resolve().parent
BASE_OUTPUT_DIR = SCRIPT_DIR / "output"
BASE_OUTPUT_DIR.mkdir(exist_ok=True)


def get_output_root(keyword_slug: Optional[str] = None) -> Path:
    if keyword_slug:
        root = BASE_OUTPUT_DIR / keyword_slug
    else:
        root = BASE_OUTPUT_DIR
    root.mkdir(parents=True, exist_ok=True)
    return root

ORIGINAL_HOME = Path.home()
PLAYWRIGHT_SANDBOX_HOME = SCRIPT_DIR / ".playwright_home"
PLAYWRIGHT_SANDBOX_HOME.mkdir(parents=True, exist_ok=True)

CRASH_DUMPS_DIR = PLAYWRIGHT_SANDBOX_HOME / "crashpad"
CRASH_DUMPS_DIR.mkdir(parents=True, exist_ok=True)

DEFAULT_PLAYWRIGHT_BROWSERS = ORIGINAL_HOME / "Library" / "Caches" / "ms-playwright"
os.environ.setdefault("PLAYWRIGHT_BROWSERS_PATH", str(DEFAULT_PLAYWRIGHT_BROWSERS))

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GENAI_LIB_AVAILABLE = genai is not None
GEMINI_AVAILABLE = False

# APIã‚­ãƒ¼ã‚’è¨­å®š
if GENAI_LIB_AVAILABLE and GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    GEMINI_AVAILABLE = True

SLICE_HEIGHT_DEFAULT = 1400
SLICE_OVERLAP_DEFAULT = 120
DESKTOP_VIEWPORT = {"width": 1400, "height": 900}
DESKTOP_USER_AGENT = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_0) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/125.0.0.0 Safari/537.36"
)


def clear_playwright_quarantine() -> None:
    if sys.platform != "darwin":
        return

    candidate_paths = {
        DEFAULT_PLAYWRIGHT_BROWSERS,
        PLAYWRIGHT_SANDBOX_HOME / "Library" / "Caches" / "ms-playwright",
    }

    browsers_path_env = os.environ.get("PLAYWRIGHT_BROWSERS_PATH")
    if browsers_path_env:
        candidate_paths.add(Path(browsers_path_env))

    for path in candidate_paths:
        if not path or not Path(path).exists():
            continue
        try:
            subprocess.run(
                ["xattr", "-dr", "com.apple.quarantine", str(path)],
                check=False,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
        except Exception:
            continue


def prepare_chromium_environment() -> None:
    if sys.platform != "darwin":
        return

    crashpad_dir = PLAYWRIGHT_SANDBOX_HOME / "Library" / "Application Support" / "Chromium" / "Crashpad"
    try:
        crashpad_dir.mkdir(parents=True, exist_ok=True)
        subprocess.run(
            ["xattr", "-dr", "com.apple.quarantine", str(crashpad_dir)],
            check=False,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )
    except Exception:
        pass


def _resolve_headless_shell():
    browsers_path = Path(os.environ.get("PLAYWRIGHT_BROWSERS_PATH", DEFAULT_PLAYWRIGHT_BROWSERS))
    if not browsers_path.exists():
        return None

    for entry in sorted(browsers_path.glob("chromium_headless_shell-*"), reverse=True):
        potential = entry / "chrome-mac" / "headless_shell"
        if potential.exists():
            return str(potential)
    return None


def build_browser_env() -> dict:
    env = os.environ.copy()
    env["HOME"] = str(PLAYWRIGHT_SANDBOX_HOME)
    env.setdefault("USER", os.environ.get("USER", "playwright"))
    return env


def launch_browser(playwright):
    launch_env = build_browser_env()

    def attempt(label, launcher):
        try:
            print(f"â„¹ï¸ {label} ã§ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚’è©¦è¡Œã—ã¾ã™ã€‚")
            return launcher()
        except Exception as error:
            print(f"âš ï¸ {label} ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {error}")
            return None

    chromium_args = [
        "--headless=new",
        "--disable-crash-reporter",
        "--disable-crashpad",
        "--disable-features=CrashReporting",
        f"--crash-dumps-dir={CRASH_DUMPS_DIR}",
    ]

    launchers = [
        ("Chromium (æ–°Headless)", lambda: playwright.chromium.launch(headless=True, args=chromium_args, env=launch_env)),
        ("Chromium (Chromeãƒãƒ£ãƒ³ãƒãƒ«)", lambda: playwright.chromium.launch(channel="chrome", headless=True, args=chromium_args, env=launch_env)),
    ]

    headless_shell_path = _resolve_headless_shell()
    if headless_shell_path:
        launchers.append(
            ("Chromium Headless Shell", lambda: playwright.chromium.launch(executable_path=headless_shell_path, headless=True, env=launch_env))
        )

    launchers.extend(
        [
            ("Firefox", lambda: playwright.firefox.launch(headless=True, env=launch_env)),
            ("WebKit", lambda: playwright.webkit.launch(headless=True, env=launch_env)),
        ]
    )

    for label, launcher in launchers:
        browser = attempt(label, launcher)
        if browser is not None:
            return browser

    raise RuntimeError("Playwrightã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚`playwright install` ã‚„ãƒ–ãƒ©ã‚¦ã‚¶ã¸ã®æ¨©é™è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Webã‚µã‚¤ãƒˆã®OCRæ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ«")
    parser.add_argument("--url", dest="url", help="æ–‡å­—èµ·ã“ã—å¯¾è±¡ã®URL")
    parser.add_argument(
        "--html-path",
        dest="html_path",
        type=Path,
        help="ãƒ­ãƒ¼ã‚«ãƒ«ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ–‡å­—èµ·ã“ã—å¯¾è±¡ã«æŒ‡å®šã—ã¾ã™",
    )
    parser.add_argument(
        "--slice-height",
        dest="slice_height",
        type=int,
        default=SLICE_HEIGHT_DEFAULT,
        help="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆåˆ†å‰²æ™‚ã®é«˜ã•(px)ã€‚å¤§ãã™ãã‚‹ã¨OCRç²¾åº¦ãŒä¸‹ãŒã‚Šã¾ã™",
    )
    parser.add_argument(
        "--overlap",
        dest="overlap",
        type=int,
        default=SLICE_OVERLAP_DEFAULT,
        help="åˆ†å‰²ç”»åƒåŒå£«ã®é‡ãªã‚Š(px)ã€‚å°ã•ã™ãã‚‹ã¨è¡ŒãŒæ¬ ã‘ã‚„ã™ããªã‚Šã¾ã™",
    )
    args = parser.parse_args()

    if args.url and args.html_path:
        parser.error("--url ã¨ --html-path ã¯åŒæ™‚ã«æŒ‡å®šã§ãã¾ã›ã‚“ã€‚")

    return args


def ensure_ocr_ready() -> None:
    if not GENAI_LIB_AVAILABLE:
        print("âš ï¸ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª `google-generativeai` ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Gemini OCRã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        print("   `pip install google-generativeai` ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¯èƒ½ã§ã™ã€‚")

    if not GOOGLE_API_KEY:
        print("âš ï¸ ç’°å¢ƒå¤‰æ•° `GOOGLE_API_KEY` ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Gemini OCRã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    if GEMINI_AVAILABLE:
        print("âœ… Gemini OCR (API) ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚")
    else:
        print("âš ï¸ Gemini OCRã‚’ä½¿ç”¨ã§ããªã„ãŸã‚ã€Playwrightã‹ã‚‰å–å¾—ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®ã¿ä¿å­˜ã—ã¾ã™ã€‚")


def resolve_local_html_path(html_path: Path) -> Path:
    """ãƒ­ãƒ¼ã‚«ãƒ«LPã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã¨ãªã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ±ºã™ã‚‹ã€‚"""

    candidate = html_path.expanduser().resolve()

    if candidate.is_dir():
        for default_name in ("index.html", "index.htm"):  # ã‚ˆãã‚ã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã‚’æ¢ç´¢
            default_path = candidate / default_name
            if default_path.exists():
                return default_path
        raise FileNotFoundError(
            f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {candidate} ã« index.html / index.htm ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        )

    if not candidate.exists():
        raise FileNotFoundError(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {candidate}")

    if candidate.is_file():
        return candidate

    raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {candidate}")


def load_page(page, url: str) -> None:
    print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ä¸­: {url}")
    try:
        # networkidleã ã‘ã§ååˆ†ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡ãŒ500msä»¥å†…ã«è½ã¡ç€ãã¾ã§å¾…ã¤ï¼‰
        page.goto(url, wait_until="networkidle", timeout=60000, referer="https://www.google.com/")
        print("âœ… ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº†")
    except PlaywrightTimeoutError:
        print("âš ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€å–å¾—å¯èƒ½ãªç¯„å›²ã§ç¶šè¡Œ")

    # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§é…å»¶èª­ã¿è¾¼ã¿ã‚’ãƒˆãƒªã‚¬ãƒ¼
    scroll_page(page)
    time.sleep(1.0)


def scroll_page(page) -> None:
    body_height = page.evaluate("() => document.body.scrollHeight")
    checkpoints = [0.25, 0.5, 0.75, 1.0]

    for ratio in checkpoints:
        target = int(body_height * ratio)
        page.evaluate("(y) => window.scrollTo({top: y, behavior: 'smooth'})", target)
        time.sleep(1.5)

    page.evaluate("() => window.scrollTo(0, 0)")
    time.sleep(1.0)


def collect_meta(page) -> Dict[str, str]:
    meta: Dict[str, str] = {"title": page.title()}

    description_locator = page.locator('meta[name="description"]')
    meta["description"] = (
        description_locator.first.get_attribute("content")
        if description_locator.count() > 0
        else ""
    ) or ""

    keywords_locator = page.locator('meta[name="keywords"]')
    meta["keywords"] = (
        keywords_locator.first.get_attribute("content")
        if keywords_locator.count() > 0
        else ""
    ) or ""

    return meta


def fetch_visible_text(page) -> str:
    return page.evaluate(
        r"""
        () => {
            const excludeSelectors = ['script', 'style', 'noscript', 'iframe'];
            excludeSelectors.forEach(selector => {
                document.querySelectorAll(selector).forEach(el => el.remove());
            });

            const text = document.body.innerText;
            return text.replace(/\n\s*\n/g, '\n\n').trim();
        }
        """
    )


def capture_page_screenshots(page, run_dir: Path, slice_height: int = 1400, overlap: int = 120) -> tuple[Path, List[Dict[str, Any]]]:
    """Playwrightã§ç›´æ¥ã‚¹ãƒ©ã‚¤ã‚¹ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    segments_dir = run_dir / "segments"
    segments_dir.mkdir(exist_ok=True)

    try:
        # ãƒšãƒ¼ã‚¸å…¨ä½“ã®é«˜ã•ã¨ãƒ“ãƒ¥ãƒ¼ãƒãƒ¼ãƒˆå¹…ã‚’å–å¾—
        total_height = page.evaluate("() => document.body.scrollHeight")
        viewport = page.viewport_size or {"width": 1400, "height": 900}
        viewport_width = viewport["width"]

        print(f"ğŸ“ ãƒšãƒ¼ã‚¸å…¨ä½“ã®é«˜ã•: {total_height}px")

        # ãƒ“ãƒ¥ãƒ¼ãƒãƒ¼ãƒˆã®é«˜ã•ã‚’slice_heightã«è¨­å®š
        page.set_viewport_size({"width": viewport_width, "height": slice_height})

        segments_meta = []
        segment_paths = []
        current_top = 0
        index = 1

        while current_top < total_height:
            # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä½ç½®ã‚’è¨­å®š
            page.evaluate(f"() => window.scrollTo(0, {current_top})")
            time.sleep(0.3)  # ç”»åƒèª­ã¿è¾¼ã¿å¾…æ©Ÿ

            # ç¾åœ¨ã®ãƒ“ãƒ¥ãƒ¼ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
            segment_path = segments_dir / f"segment_{index:04d}.png"
            page.screenshot(path=str(segment_path), full_page=False)

            # å®Ÿéš›ã®é«˜ã•ã‚’è¨ˆç®—
            actual_height = min(slice_height, total_height - current_top)

            segments_meta.append({
                "index": index,
                "path": str(segment_path),
                "top": current_top,
                "bottom": current_top + actual_height,
            })
            segment_paths.append(segment_path)

            print(f"  ğŸ“¸ ã‚¹ãƒ©ã‚¤ã‚¹ #{index} ({current_top}px ~ {current_top + actual_height}px)")

            # æ¬¡ã®ã‚¹ãƒ©ã‚¤ã‚¹ä½ç½®ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚’è€ƒæ…®ï¼‰
            current_top += slice_height - overlap
            index += 1

            # æœ€å¾Œã®ã‚¹ãƒ©ã‚¤ã‚¹ã‚’è¶…ãˆãŸå ´åˆã¯çµ‚äº†
            if current_top >= total_height:
                break

        # ãƒ“ãƒ¥ãƒ¼ãƒãƒ¼ãƒˆã‚’å…ƒã«æˆ»ã™
        page.set_viewport_size(viewport)
        page.evaluate("() => window.scrollTo(0, 0)")

        print(f"âœ… {len(segments_meta)} å€‹ã®ã‚¹ãƒ©ã‚¤ã‚¹ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")

        # ãƒ•ãƒ«ãƒšãƒ¼ã‚¸ç”»åƒã‚’çµåˆ
        screenshot_path = run_dir / "full_page.png"
        merge_segment_images(segment_paths, screenshot_path)
        print(f"âœ… ãƒ•ãƒ«ãƒšãƒ¼ã‚¸ç”»åƒã‚’çµåˆã—ã¾ã—ãŸ")

        return screenshot_path, segments_meta

    except Exception as error:
        print(f"âš ï¸ ãƒ•ãƒ«ãƒšãƒ¼ã‚¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå–å¾—ã«å¤±æ•—ã—ãŸãŸã‚ã€åˆ†å‰²ã‚­ãƒ£ãƒ—ãƒãƒ£ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™: {error}")
        segment_paths = capture_fallback_segments(page, run_dir, parts=2)

        segments_meta = []
        offset = 0
        for idx, segment_path in enumerate(segment_paths, start=1):
            with Image.open(segment_path) as img:
                height = img.height
            segments_meta.append(
                {
                    "index": idx,
                    "path": str(segment_path),
                    "top": offset,
                    "bottom": offset + height,
                }
            )
            offset += height

        try:
            merge_segment_images(segment_paths, screenshot_path)
        except Exception as merge_error:
            print(f"âš ï¸ åˆ†å‰²ç”»åƒã®çµåˆã«å¤±æ•—ã—ã¾ã—ãŸ: {merge_error}")

        return screenshot_path, segments_meta


def capture_full_page_screenshot(page, path: Path) -> None:
    page.screenshot(
        path=str(path),
        full_page=True,
        animations="disabled",
        timeout=120_000,
    )


def capture_fallback_segments(
    page,
    run_dir: Path,
    parts: Optional[int] = None,
) -> List[Path]:
    segments_dir = run_dir / "segments"
    segments_dir.mkdir(exist_ok=True)

    viewport = page.viewport_size or DESKTOP_VIEWPORT
    width = viewport["width"]
    viewport_height = viewport["height"] or 1

    total_height = page.evaluate("() => document.body.scrollHeight")
    if parts is None:
        required_parts = math.ceil(total_height / viewport_height)
    else:
        required_parts = max(parts, math.ceil(total_height / viewport_height))

    required_parts = max(1, required_parts)
    step = max(total_height // required_parts, viewport_height)

    paths: List[Path] = []
    for index in range(required_parts):
        scroll_top = min(index * step, max(0, total_height - viewport_height))
        page.evaluate("(y) => window.scrollTo(0, y)", scroll_top)
        time.sleep(1.5)

        clip_height = min(viewport_height, total_height - scroll_top)
        if clip_height <= 0:
            break

        segment_path = segments_dir / f"segment_{index + 1:02d}.png"
        page.screenshot(
            path=str(segment_path),
            full_page=False,
            animations="disabled",
            timeout=120_000,
            clip={
                "x": 0,
                "y": 0,
                "width": width,
                "height": clip_height,
            },
        )
        paths.append(segment_path)

    page.evaluate("() => window.scrollTo(0, 0)")

    if not paths:
        raise RuntimeError("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    return paths


def load_and_capture(
    context,
    url: str,
    run_dir: Path,
    slice_height: int = 1400,
    overlap: int = 120,
) -> tuple:
    page = context.new_page()
    load_page(page, url)
    meta = collect_meta(page)
    visible_text = ""  # Playwright HTMLæŠ½å‡ºã‚’ç„¡åŠ¹åŒ–
    screenshot_path, segments_meta = capture_page_screenshots(page, run_dir, slice_height, overlap)
    return page, meta, visible_text, screenshot_path, segments_meta


def sanitize_html_for_static_render(html: str, base_url: str) -> str:
    cleaned = re.sub(r"<script\b[^<]*(?:(?!</script>)<[^<]*)*</script>", "", html, flags=re.IGNORECASE | re.DOTALL)
    if "<base" not in cleaned.lower():
        head_insertion = "<head>"
        base_tag = f"<base href=\"{base_url}\">"
        if head_insertion in cleaned:
            cleaned = cleaned.replace(head_insertion, head_insertion + base_tag, 1)
        else:
            cleaned = base_tag + cleaned
    return cleaned


def capture_static_render(
    playwright,
    url: str,
    run_dir: Path,
    context_options: dict,
    slice_height: int = 1400,
    overlap: int = 120,
) -> tuple[Dict[str, str], str, Path, List[Dict[str, Any]]]:
    if requests is None:
        raise RuntimeError("requests ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€HTMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ–¹å¼ã®ã‚­ãƒ£ãƒ—ãƒãƒ£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    headers = {
        "User-Agent": DESKTOP_USER_AGENT,
        "Referer": "https://www.google.com/",
    }
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
    except Exception as error:
        raise RuntimeError(f"HTMLã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {error}") from error

    sanitized_html = sanitize_html_for_static_render(response.text, base_url=url)

    browser = launch_browser(playwright)
    context = browser.new_context(**context_options)
    page = None
    try:
        page = context.new_page()
        page.set_content(sanitized_html, wait_until="load", timeout=120000)
        meta = collect_meta(page)
        visible_text = ""  # Playwright HTMLæŠ½å‡ºã‚’ç„¡åŠ¹åŒ–
        screenshot_path, segments_meta = capture_page_screenshots(page, run_dir, slice_height, overlap)
    finally:
        if page and not page.is_closed():
            try:
                page.close()
            except PlaywrightError:
                pass
        try:
            context.close()
        except PlaywrightError:
            pass
        try:
            browser.close()
        except PlaywrightError:
            pass

    return meta, visible_text, screenshot_path, segments_meta


def merge_segment_images(segment_paths: List[Path], output_path: Path) -> None:
    images = [Image.open(p).convert("RGB") for p in segment_paths]
    try:
        width = max(img.width for img in images)
        total_height = sum(img.height for img in images)
        merged = Image.new("RGB", (width, total_height), color=(255, 255, 255))

        current_y = 0
        for img in images:
            merged.paste(img, (0, current_y))
            current_y += img.height

        merged.save(output_path)
    finally:
        for img in images:
            img.close()


def extract_text_from_genai_response(response) -> str:
    if response is None:
        return ""

    text = getattr(response, "text", None)
    if text:
        return text

    texts: List[str] = []
    for candidate in getattr(response, "candidates", []) or []:
        content = getattr(candidate, "content", None)
        parts = getattr(content, "parts", []) if content else []
        for part in parts:
            part_text = getattr(part, "text", None)
            if part_text:
                texts.append(part_text)
    return "\n".join(texts)


def run_gemini_ocr(image_path: str) -> str:
    """
    Gemini APIã‚’å‘¼ã³å‡ºã—ã¦ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹
    """
    if not GEMINI_AVAILABLE:
        return ""

    try:
        print(f"    - Gemini APIã§OCRå‡¦ç†ä¸­: {Path(image_path).name}")
        model = genai.GenerativeModel("gemini-2.0-flash-exp")
        
        # ç”»åƒã‚’ç›´æ¥èª­ã¿è¾¼ã‚“ã§é€ä¿¡ï¼ˆupload_fileã‚’ä½¿ã‚ãªã„æ–¹æ³•ï¼‰
        from PIL import Image
        img = Image.open(image_path)
        image_file = img
        try:
            response = model.generate_content(
                [
                    """# å‘½ä»¤
ã‚ãªãŸã¯ã€Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨UXã®æ§‹é€ ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ã“ã‚Œã‹ã‚‰é€ä»˜ã•ã‚Œã‚‹è¤‡æ•°ã®ç”»åƒï¼ˆãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã‚’ä¸Šã‹ã‚‰é †ã«ã‚¹ãƒ©ã‚¤ã‚¹ã—ãŸã‚‚ã®ï¼‰ã‚’åˆ†æã—ã€ãã®æ§‹æˆã¨æ–‡è„ˆã‚’å®Œå…¨ã«å†ç¾ã—ãŸä¸Šã§ã€å†…å®¹ã‚’Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦é«˜å“è³ªãªæ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚

---

# èƒŒæ™¯ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
- **å¯¾è±¡:** ã‚ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒšãƒ¼ã‚¸ï¼ˆLPï¼‰
- **å…¥åŠ›ãƒ‡ãƒ¼ã‚¿:** LPã‚’ä¸Šã‹ã‚‰é †ã«åˆ†å‰²ã—ãŸä¸€é€£ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€‚
- **æœ€çµ‚ç›®æ¨™:** ç”»åƒã«å«ã¾ã‚Œã‚‹æƒ…å ±ã‚’ã€å…ƒã®LPã®è«–ç†çš„ãªæµã‚Œã‚„éšå±¤æ§‹é€ ï¼ˆè¦‹å‡ºã—ã€æœ¬æ–‡ã€ç®‡æ¡æ›¸ãã€CTAãªã©ï¼‰ã‚’ä¿æŒã—ãŸã¾ã¾ã€å˜ä¸€ã®Markdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å†æ§‹æˆã™ã‚‹ã“ã¨ã€‚å˜ãªã‚‹æ–‡å­—ã®æŠœãå‡ºã—ã§ã¯ãªãã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ä¸Šã®æ–‡è„ˆã‚’ç†è§£ã—ãŸä¸Šã§ã®å†æ§‹æˆã‚’æ±‚ã‚ã¾ã™ã€‚

---

# å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—
1.  æä¾›ã•ã‚ŒãŸç”»åƒã‚’ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚„é€ä¿¡ã•ã‚ŒãŸé †ç•ªé€šã‚Šã«ã€ä¸Šã‹ã‚‰ä¸‹ã¸ã®æµã‚Œã¨ã—ã¦èªè­˜ã—ã¦ãã ã•ã„ã€‚
2.  å„ç”»åƒã®å†…å®¹ã‚’åˆ†æã—ã€ãã‚ŒãŒLPã®ã©ã®æ§‹æˆè¦ç´ ï¼ˆä¾‹: ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼ã€å•é¡Œæèµ·ã€è§£æ±ºç­–ã®æç¤ºã€ãŠå®¢æ§˜ã®å£°ã€CTAï¼‰ã«è©²å½“ã™ã‚‹ã‹ã‚’é ­ã®ä¸­ã§æŠŠæ¡ã—ã¾ã™ã€‚
3.  ç”»åƒã«å«ã¾ã‚Œã‚‹å…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€ä¸€è¨€ä¸€å¥æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã—ã¾ã™ã€‚
4.  ãƒ†ã‚­ã‚¹ãƒˆã®å½¹å‰²ï¼ˆå¤§è¦‹å‡ºã—ã€å°è¦‹å‡ºã—ã€æœ¬æ–‡ã€ç®‡æ¡æ›¸ãã€ãƒœã‚¿ãƒ³ã®æ–‡è¨€ãªã©ï¼‰ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚
5.  åˆ¤æ–­ã—ãŸå½¹å‰²ã«åŸºã¥ãã€ä»¥ä¸‹ã®å‡ºåŠ›å½¢å¼ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€å…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜ä¸€ã®Markdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ•´å½¢ã—ã€å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

---

# å‡ºåŠ›å½¢å¼
- **å¤§è¦‹å‡ºã— (H1):** `# è¦‹å‡ºã—`
- **ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã— (H2):** `## ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã—`
- **å°è¦‹å‡ºã— (H3):** `### å°è¦‹å‡ºã—`
- **æœ¬æ–‡:** é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
- **å¼·èª¿:** å¤ªå­—ã§è¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ç®‡æ‰€ã¯ `**å¼·èª¿ãƒ†ã‚­ã‚¹ãƒˆ**` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
- **ç®‡æ¡æ›¸ã:** `- ãƒªã‚¹ãƒˆé …ç›®` ã®å½¢å¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
- **ãŠå®¢æ§˜ã®å£°ã‚„å¼•ç”¨:** `> å¼•ç”¨æ–‡` ã®å½¢å¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
- **ã‚³ãƒ¼ãƒ«ãƒˆã‚¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ (CTA) / ãƒœã‚¿ãƒ³:** `[CTA] ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆ` ã¨ã„ã†å½¢å¼ã§æ˜ç¢ºã«ç¤ºã—ã¦ãã ã•ã„ã€‚

---

# åˆ¶ç´„äº‹é …
- ç”»åƒã«å«ã¾ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯ã€è£…é£¾çš„ãªã‚‚ã®ã§ã‚ã£ã¦ã‚‚åŸå‰‡ã¨ã—ã¦ã™ã¹ã¦æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚
- ç”»åƒã®é †ç•ªã‚’LPã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°ã®é †ç•ªã¨ã¿ãªã—ã€å³å®ˆã—ã¦ãã ã•ã„ã€‚
- ã‚ãªãŸè‡ªèº«ã®æ„è¦‹ã‚„è¿½åŠ æƒ…å ±ã¯å«ã‚ãšã€ç”»åƒã®å†…å®¹ã®ã¿ã‚’å¿ å®Ÿã«å†ç¾ã—ã¦ãã ã•ã„ã€‚
""",
                    image_file,
                ],
                generation_config={"temperature": 0.0},
            )
        finally:
            # ç”»åƒã‚’ç›´æ¥æ¸¡ã—ã¦ã„ã‚‹ã®ã§å‰Šé™¤ä¸è¦
            pass

        text = extract_text_from_genai_response(response).strip()
        return text

    except Exception as e:
        print(f"âŒ Gemini APIã®å‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return ""


def run_ocr_on_segments(segments: List[Dict[str, any]]) -> List[Dict[str, any]]:
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®OCRã‚’ä¸¦åˆ—å‡¦ç†ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    if not GEMINI_AVAILABLE:
        print("âš ï¸ Gemini OCRãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€OCRã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        results = []
        for segment in segments:
            results.append(
                {
                    "index": segment["index"],
                    "path": Path(segment["path"]),
                    "top": segment["top"],
                    "bottom": segment["bottom"],
                    "raw_text": "",
                    "clean_text": "",
                }
            )
        return results

    print(f"ğŸ” {len(segments)} å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’Geminiã§ä¸¦åˆ—OCRå‡¦ç†ä¸­...")

    def process_single_segment(segment):
        """å˜ä¸€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®OCRå‡¦ç†"""
        try:
            print(f"  ğŸ” ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment['index']} å‡¦ç†ä¸­...")
            ocr_raw = run_gemini_ocr(segment["path"])
            raw_text = ocr_raw.strip()
            clean_text = clean_ocr_text(raw_text)

            return {
                "index": segment["index"],
                "path": Path(segment["path"]),
                "top": segment["top"],
                "bottom": segment["bottom"],
                "raw_text": raw_text,
                "clean_text": clean_text,
            }
        except Exception as e:
            print(f"  âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment['index']} ã®OCRã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "index": segment["index"],
                "path": Path(segment["path"]),
                "top": segment["top"],
                "bottom": segment["bottom"],
                "raw_text": "",
                "clean_text": "",
            }

    # ThreadPoolExecutorã§ä¸¦åˆ—å‡¦ç†ï¼ˆæœ€å¤§3ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰
    from concurrent.futures import ThreadPoolExecutor, as_completed

    results = []
    with ThreadPoolExecutor(max_workers=3) as executor:
        future_to_segment = {executor.submit(process_single_segment, seg): seg for seg in segments}

        for future in as_completed(future_to_segment):
            result = future.result()
            results.append(result)

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã‚½ãƒ¼ãƒˆ
    results.sort(key=lambda x: x["index"])

    print(f"âœ… {len(results)} å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®OCRå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
    return results


def clean_ocr_text(raw_text: str) -> str:
    if not raw_text:
        return ""

    lines = []
    for line in raw_text.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        if re.fullmatch(r"[\W_]+", stripped):
            continue
        lines.append(stripped)

    if not lines:
        return ""

    paragraphs: List[str] = []
    buffer: List[str] = []

    for line in lines:
        buffer.append(line)
        if line.endswith(("ã€‚", "ï¼", "ï¼Ÿ", "!", "?")) or len(line) > 40:
            paragraphs.append("".join(buffer))
            buffer = []

    if buffer:
        paragraphs.append("".join(buffer))

    deduped: List[str] = []
    seen = set()

    for paragraph in paragraphs:
        key = paragraph.replace(" ", "")
        if key in seen:
            continue
        seen.add(key)
        deduped.append(paragraph)

    return "\n".join(deduped)


def combine_clean_segments(segments: List[Dict[str, str]]) -> str:
    combined: List[str] = []
    seen = set()

    for segment in segments:
        text = segment.get("clean_text", "").strip()
        if not text:
            continue

        for paragraph in [p.strip() for p in text.split("\n") if p.strip()]:
            if paragraph in seen:
                continue
            seen.add(paragraph)
            combined.append(paragraph)

    return "\n\n".join(combined)


def save_markdown(result: Dict) -> Path:
    md_path = result["run_dir"] / "website_transcription.md"

    with open(md_path, "w", encoding="utf-8") as f:
        f.write("# Webã‚µã‚¤ãƒˆOCRæ–‡å­—èµ·ã“ã—çµæœ\n\n")
        f.write(f"**URL:** {result['url']}\n\n")
        f.write(f"**æŠ½å‡ºæ—¥æ™‚:** {result['timestamp']}\n\n")
        f.write(f"**ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ:** {result['screenshot'].name}\n\n")

        if result.get("source_type") == "local_html" and result.get("source_path"):
            f.write(f"**ãƒ­ãƒ¼ã‚«ãƒ«HTML:** {result['source_path']}\n\n")
        f.write(f"**åˆ†å‰²æ•°:** {len(result['segments'])} æš\n\n")

        if result.get("meta"):
            f.write("## ãƒ¡ã‚¿æƒ…å ±\n\n")
            f.write(f"- ã‚¿ã‚¤ãƒˆãƒ«: {result['meta'].get('title', '')}\n")
            if result['meta'].get('description'):
                f.write(
                    f"- èª¬æ˜: {result['meta'].get('description', '').strip()}\n"
                )
            if result['meta'].get('keywords'):
                f.write(f"- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {result['meta'].get('keywords', '').strip()}\n")
            f.write("\n")

        if result.get("combined_text"):
            f.write("## æ•´ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ\n\n")
            f.write(result["combined_text"] + "\n\n")

        # PlaywrightæŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ï¼ˆOCRã®ã¿ä½¿ç”¨ï¼‰

        f.write("## OCRã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°\n\n")
        for segment in result["segments"]:
            f.write(f"### ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {segment['index']:02d}\n\n")
            f.write(f"- ãƒ•ã‚¡ã‚¤ãƒ«: {segment['path'].name}\n")
            f.write(
                f"- ä½ç½®: {segment['top']}px ã€œ {segment['bottom']}px\n\n"
            )

            if segment.get("clean_text"):
                f.write("**æ•´å½¢ãƒ†ã‚­ã‚¹ãƒˆ**\n\n")
                f.write("```\n")
                f.write(segment["clean_text"])
                f.write("\n```\n\n")

            if segment.get("raw_text") and segment.get("raw_text") != segment.get("clean_text"):
                f.write("**OCRç”Ÿãƒ†ã‚­ã‚¹ãƒˆ**\n\n")
                f.write("```\n")
                f.write(segment["raw_text"])
                f.write("\n```\n\n")

    return md_path


def save_plain_text(result: Dict) -> Path:
    txt_path = result["run_dir"] / "website_transcription.txt"

    with open(txt_path, "w", encoding="utf-8") as f:
        if result.get("combined_text"):
            f.write(result["combined_text"])
        # visible_textã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‰Šé™¤ï¼ˆOCRã®ã¿ä½¿ç”¨ï¼‰

    return txt_path


def cleanup_segment_images(result: Dict) -> None:
    segments_dir = result["run_dir"] / "segments"
    if segments_dir.exists():
        try:
            shutil.rmtree(segments_dir)
            print("ğŸ§¹ åˆ†å‰²ã‚­ãƒ£ãƒ—ãƒãƒ£ç”»åƒã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        except Exception as cleanup_error:
            print(f"âš ï¸ åˆ†å‰²ç”»åƒã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {cleanup_error}")


def update_latest_symlink(run_dir: Path, output_root: Optional[Path] = None) -> None:
    base_root = output_root or run_dir.parent
    latest_link = base_root / "latest"

    try:
        if latest_link.is_symlink() or latest_link.exists():
            if latest_link.is_dir() and not latest_link.is_symlink():
                shutil.rmtree(latest_link)
            else:
                latest_link.unlink()

        latest_link.symlink_to(run_dir, target_is_directory=True)
        print(f"ğŸ” æœ€æ–°å‡ºåŠ›ã¸ã®ãƒªãƒ³ã‚¯ã‚’æ›´æ–°ã—ã¾ã—ãŸ: {latest_link} -> {run_dir}")
    except Exception as link_error:
        print(f"âš ï¸ æœ€æ–°å‡ºåŠ›ãƒªãƒ³ã‚¯ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {link_error}")


def transcribe_website(
    url: str,
    slice_height: int,
    overlap: int,
    keyword_slug: Optional[str] = None,
    *,
    source_type: str = "url",
    source_path: Optional[Path] = None,
) -> Dict:
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    output_root = get_output_root(keyword_slug)
    run_dir = output_root / f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    run_dir.mkdir(parents=True, exist_ok=True)

    screenshot_path: Optional[Path] = None

    with sync_playwright() as playwright:
        clear_playwright_quarantine()
        prepare_chromium_environment()
        context_options = {
            "locale": "ja-JP",
            "timezone_id": "Asia/Tokyo",
            "viewport": DESKTOP_VIEWPORT,
            "user_agent": DESKTOP_USER_AGENT,
            "is_mobile": False,
            "has_touch": False,
            "device_scale_factor": 1,
            "bypass_csp": True,
            "extra_http_headers": {
                "Referer": "https://www.google.com/",
            },
        }

        meta: Dict[str, str] = {}
        visible_text = ""
        segments_meta: List[Dict[str, int]] = []
        screenshot_path: Optional[Path] = None

        capture_success = False
        capture_error: Optional[Exception] = None

        for attempt in range(2):
            local_context_options = dict(context_options)
            if attempt == 1:
                print("âš ï¸ JavaScriptã‚’ç„¡åŠ¹åŒ–ã—ã¦å†è©¦è¡Œã—ã¾ã™ã€‚")
                local_context_options["java_script_enabled"] = False
            browser = launch_browser(playwright)
            context = browser.new_context(**local_context_options)
            try:
                context.add_init_script("""
                    (function() {
                        const noop = function noop() {};
                        try {
                            Object.defineProperty(window, 'close', { value: noop, configurable: true });
                        } catch (_) {
                            window.close = noop;
                        }
                        try {
                            window.open = function() { return window; };
                        } catch (_) {}
                        try {
                            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                        } catch (_) {}
                        try {
                            delete window.__nightmare;
                            delete window.__selenium_unwrapped;
                            delete window._Selenium_IDE_Recorder;
                        } catch (_) {}
                    })();
                """)
            except PlaywrightError:
                pass
            page = None
            try:
                if attempt > 0:
                    print("ğŸ” ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’å†è©¦è¡Œã—ã¾ã™ã€‚")
                page, meta, visible_text, screenshot_path, segments_meta = load_and_capture(
                    context=context,
                    url=url,
                    run_dir=run_dir,
                    slice_height=slice_height,
                    overlap=overlap,
                )
            except Exception as error:
                capture_error = error
                attempt_no = attempt + 1
                print(f"âš ï¸ ãƒšãƒ¼ã‚¸ã‚­ãƒ£ãƒ—ãƒãƒ£ã«å¤±æ•—ã—ã¾ã—ãŸ (è©¦è¡Œ{attempt_no}): {error}")
            else:
                capture_success = True
                break
            finally:
                if page and not page.is_closed():
                    try:
                        page.close()
                    except PlaywrightError:
                        pass
                try:
                    context.close()
                except PlaywrightError:
                    pass
                try:
                    browser.close()
                except PlaywrightError:
                    pass

        if not capture_success or not screenshot_path:
            print("âš ï¸ é€šå¸¸ã®ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œã§ãƒšãƒ¼ã‚¸ã‚’ä¿æŒã§ããªã‹ã£ãŸãŸã‚ã€HTMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ–¹å¼ã§å†è©¦è¡Œã—ã¾ã™ã€‚")
            try:
                meta, visible_text, screenshot_path, segments_meta = capture_static_render(
                    playwright=playwright,
                    url=url,
                    run_dir=run_dir,
                    context_options=dict(context_options),
                    slice_height=slice_height,
                    overlap=overlap,
                )
                capture_success = True
            except Exception as fallback_error:
                raise RuntimeError(
                    "ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                    + (f" åŸå› : {capture_error}" if capture_error else "")
                    + f" / HTMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ–¹å¼ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {fallback_error}"
                ) from fallback_error

    if not segments_meta:
        segments_meta = [
            {
                "index": 1,
                "path": str(screenshot_path) if screenshot_path else "",
                "top": 0,
                "bottom": 0,
            }
        ]

    if not screenshot_path:
        raise RuntimeError("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    ocr_segments = run_ocr_on_segments(segments_meta)
    combined_text = combine_clean_segments(ocr_segments)

    if not combined_text:
        combined_text = visible_text

    result = {
        "url": url,
        "timestamp": timestamp,
        "run_dir": run_dir,
        "screenshot": screenshot_path,
        "segments": ocr_segments,
        "combined_text": combined_text,
        "visible_text": visible_text,
        "meta": meta,
        "slice_height": slice_height,
        "overlap": overlap,
        "keyword_slug": keyword_slug,
        "output_root": output_root,
        "source_type": source_type,
    }

    if source_path is not None:
        result["source_path"] = str(source_path)

    return result


def transcribe_local_html(
    html_path: Path,
    slice_height: int,
    overlap: int,
    keyword_slug: Optional[str] = None,
) -> Dict:
    """ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã•ã‚ŒãŸLPã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼†æ–‡å­—èµ·ã“ã—ã™ã‚‹ã€‚"""

    resolved_html = resolve_local_html_path(html_path)
    file_url = resolved_html.as_uri()

    return transcribe_website(
        url=file_url,
        slice_height=slice_height,
        overlap=overlap,
        keyword_slug=keyword_slug,
        source_type="local_html",
        source_path=resolved_html,
    )


def main() -> None:
    args = parse_args()
    ensure_ocr_ready()

    target_mode = "url"
    target_url: Optional[str] = None
    target_html: Optional[Path] = None

    if args.html_path is not None:
        target_mode = "local_html"
        target_html = args.html_path
    else:
        candidate = args.url or input("æ–‡å­—èµ·ã“ã—å¯¾è±¡ã®URLã¾ãŸã¯ãƒ­ãƒ¼ã‚«ãƒ«HTMLãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
        if not candidate:
            print("âŒ URL / HTMLãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            sys.exit(1)

        potential_path = Path(candidate).expanduser()
        if potential_path.exists():
            target_mode = "local_html"
            target_html = potential_path
        else:
            target_url = candidate

    print("=" * 70)
    print("ğŸŒ Webã‚µã‚¤ãƒˆOCRæ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ« (Geminiç‰ˆ)")
    print("=" * 70)

    if target_mode == "local_html":
        assert target_html is not None
        result = transcribe_local_html(
            html_path=target_html,
            slice_height=args.slice_height,
            overlap=args.overlap,
        )
    else:
        assert target_url is not None
        result = transcribe_website(
            url=target_url,
            slice_height=args.slice_height,
            overlap=args.overlap,
        )

    md_path = save_markdown(result)
    txt_path = save_plain_text(result)
    cleanup_segment_images(result)
    update_latest_symlink(result["run_dir"], output_root=result.get("output_root"))

    print("\n" + "=" * 70)
    print("ğŸ‰ å‡¦ç†å®Œäº†ï¼")
    print("=" * 70)
    print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {result['run_dir']}")
    print(f"- Markdown: {md_path.name}")
    print(f"- ãƒ†ã‚­ã‚¹ãƒˆ : {txt_path.name}")
    print(f"- ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ: {result['screenshot'].name}")
    print(f"- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(result['segments'])}")


if __name__ == "__main__":
    main()
